{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd040b3fa18ff9822955ade3b4293c8055f93f4db314a02c83cb9a8d0e03e1ce95a",
   "display_name": "Python 3.8.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Detection of TOXicity in comments in Spanish (DETOXIS 2021)\n",
    "\n",
    "## SESIÓN 2.2: Clasificación\n",
    "\n",
    "### Realizado por Álvaro Mazcuñán y Miquel Marín"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Librerías"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Se importan las mismas librerías que se utilizaron en la parte anterior"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "source": [
    "#### Datos de DETOXIS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "A continuación se cargan los datos tal y como se hizo en la anterior entrega"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     topic thread_id comment_id reply_to  comment_level  \\\n",
       "0       CR     0_000      0_002    0_002              1   \n",
       "1       CR     0_001      0_003    0_003              1   \n",
       "2       CR     0_002      0_004    0_004              1   \n",
       "3       CR     0_003      0_005    0_005              1   \n",
       "4       CR     0_004      0_006    0_006              1   \n",
       "...    ...       ...        ...      ...            ...   \n",
       "3458    MI    20_134     20_164   20_164              1   \n",
       "3459    MI    20_006     20_165   20_008              2   \n",
       "3460    MI    20_135     20_166   20_166              1   \n",
       "3461    MI    20_136     20_167   20_167              1   \n",
       "3462    MI    20_137     20_168   20_168              1   \n",
       "\n",
       "                                                comment  argumentation  \\\n",
       "0                              Pensó: Zumo para restar.              0   \n",
       "1      Como les gusta el afeitado en seco a esta gente.              0   \n",
       "2     asi me gusta, que se maten entre ellos y en al...              0   \n",
       "3     Loss mas valientes, los que mejor cortan nuest...              0   \n",
       "4                                         Costumbres...              0   \n",
       "...                                                 ...            ...   \n",
       "3458                   Ya decía yo que veía menos moros              0   \n",
       "3459                               +1. Como lo sabes...              0   \n",
       "3460  Seguirán cobrando paguitas en Marruecos,expoli...              0   \n",
       "3461  pobres, se arriesgan en pateras porque huyen d...              0   \n",
       "3462  Yo me quiero escapar también, dan paguita al l...              0   \n",
       "\n",
       "      constructiveness  positive_stance  negative_stance  ...  target_group  \\\n",
       "0                    0                0                0  ...             0   \n",
       "1                    0                0                0  ...             1   \n",
       "2                    0                0                0  ...             1   \n",
       "3                    0                0                0  ...             1   \n",
       "4                    0                0                0  ...             1   \n",
       "...                ...              ...              ...  ...           ...   \n",
       "3458                 0                0                0  ...             1   \n",
       "3459                 0                1                0  ...             0   \n",
       "3460                 0                0                0  ...             1   \n",
       "3461                 0                0                0  ...             1   \n",
       "3462                 0                0                0  ...             0   \n",
       "\n",
       "      stereotype  sarcasm  mockery  insult  improper_language  aggressiveness  \\\n",
       "0              0        0        1       0                  0               0   \n",
       "1              1        1        1       0                  0               0   \n",
       "2              0        0        0       0                  0               1   \n",
       "3              0        1        1       0                  0               0   \n",
       "4              1        0        0       0                  0               0   \n",
       "...          ...      ...      ...     ...                ...             ...   \n",
       "3458           0        0        1       1                  0               0   \n",
       "3459           0        0        0       0                  0               0   \n",
       "3460           1        0        0       0                  0               0   \n",
       "3461           0        0        1       0                  0               0   \n",
       "3462           0        0        1       0                  0               0   \n",
       "\n",
       "      intolerance  toxicity  toxicity_level  \n",
       "0               0         1               1  \n",
       "1               0         1               1  \n",
       "2               1         1               2  \n",
       "3               0         1               1  \n",
       "4               0         1               1  \n",
       "...           ...       ...             ...  \n",
       "3458            0         1               1  \n",
       "3459            0         0               0  \n",
       "3460            1         1               1  \n",
       "3461            0         1               1  \n",
       "3462            0         1               1  \n",
       "\n",
       "[3463 rows x 21 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic</th>\n      <th>thread_id</th>\n      <th>comment_id</th>\n      <th>reply_to</th>\n      <th>comment_level</th>\n      <th>comment</th>\n      <th>argumentation</th>\n      <th>constructiveness</th>\n      <th>positive_stance</th>\n      <th>negative_stance</th>\n      <th>...</th>\n      <th>target_group</th>\n      <th>stereotype</th>\n      <th>sarcasm</th>\n      <th>mockery</th>\n      <th>insult</th>\n      <th>improper_language</th>\n      <th>aggressiveness</th>\n      <th>intolerance</th>\n      <th>toxicity</th>\n      <th>toxicity_level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CR</td>\n      <td>0_000</td>\n      <td>0_002</td>\n      <td>0_002</td>\n      <td>1</td>\n      <td>Pensó: Zumo para restar.</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CR</td>\n      <td>0_001</td>\n      <td>0_003</td>\n      <td>0_003</td>\n      <td>1</td>\n      <td>Como les gusta el afeitado en seco a esta gente.</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CR</td>\n      <td>0_002</td>\n      <td>0_004</td>\n      <td>0_004</td>\n      <td>1</td>\n      <td>asi me gusta, que se maten entre ellos y en al...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CR</td>\n      <td>0_003</td>\n      <td>0_005</td>\n      <td>0_005</td>\n      <td>1</td>\n      <td>Loss mas valientes, los que mejor cortan nuest...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CR</td>\n      <td>0_004</td>\n      <td>0_006</td>\n      <td>0_006</td>\n      <td>1</td>\n      <td>Costumbres...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3458</th>\n      <td>MI</td>\n      <td>20_134</td>\n      <td>20_164</td>\n      <td>20_164</td>\n      <td>1</td>\n      <td>Ya decía yo que veía menos moros</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3459</th>\n      <td>MI</td>\n      <td>20_006</td>\n      <td>20_165</td>\n      <td>20_008</td>\n      <td>2</td>\n      <td>+1. Como lo sabes...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3460</th>\n      <td>MI</td>\n      <td>20_135</td>\n      <td>20_166</td>\n      <td>20_166</td>\n      <td>1</td>\n      <td>Seguirán cobrando paguitas en Marruecos,expoli...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3461</th>\n      <td>MI</td>\n      <td>20_136</td>\n      <td>20_167</td>\n      <td>20_167</td>\n      <td>1</td>\n      <td>pobres, se arriesgan en pateras porque huyen d...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3462</th>\n      <td>MI</td>\n      <td>20_137</td>\n      <td>20_168</td>\n      <td>20_168</td>\n      <td>1</td>\n      <td>Yo me quiero escapar también, dan paguita al l...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>3463 rows × 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/mique/Documents/CURSO 3 - SEMESTRE B/LENGUAJE NATURAL Y RECUPERACION DE LA INFORMACION/PRACTICAS/DATASET_DETOXIS.csv')\n",
    "data"
   ]
  },
  {
   "source": [
    "#### Problema del desbalance de clases"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Debido a que se van a usar algoritmos de clasificación se tendría que estudiar, para los dos variables de `toxicity` y `toxicity_level`, si dichas clases están balanceadas o no debido a que en problemas de clasificación se suelen encontrar que en el conjunto de datos de entrenamiento una de las clases es minoritaria, es decir, en ella hay muy pocas muestras. Esto puede llegar a afectar a los algoritmos en su proceso de generalización y, en consecuencia, no poder diferenciar una clase de la otra."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    2316\n",
       "1    1147\n",
       "Name: toxicity, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "data[\"toxicity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    2317\n",
       "1     808\n",
       "2     269\n",
       "3      69\n",
       "Name: toxicity_level, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "data[\"toxicity_level\"].value_counts()"
   ]
  },
  {
   "source": [
    "#### Subset de variables para el análisis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                comment  toxicity  \\\n",
       "0                              Pensó: Zumo para restar.         1   \n",
       "1      Como les gusta el afeitado en seco a esta gente.         1   \n",
       "2     asi me gusta, que se maten entre ellos y en al...         1   \n",
       "3     Loss mas valientes, los que mejor cortan nuest...         1   \n",
       "4                                         Costumbres...         1   \n",
       "...                                                 ...       ...   \n",
       "3458                   Ya decía yo que veía menos moros         1   \n",
       "3459                               +1. Como lo sabes...         0   \n",
       "3460  Seguirán cobrando paguitas en Marruecos,expoli...         1   \n",
       "3461  pobres, se arriesgan en pateras porque huyen d...         1   \n",
       "3462  Yo me quiero escapar también, dan paguita al l...         1   \n",
       "\n",
       "      toxicity_level  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  2  \n",
       "3                  1  \n",
       "4                  1  \n",
       "...              ...  \n",
       "3458               1  \n",
       "3459               0  \n",
       "3460               1  \n",
       "3461               1  \n",
       "3462               1  \n",
       "\n",
       "[3463 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment</th>\n      <th>toxicity</th>\n      <th>toxicity_level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Pensó: Zumo para restar.</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Como les gusta el afeitado en seco a esta gente.</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>asi me gusta, que se maten entre ellos y en al...</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Loss mas valientes, los que mejor cortan nuest...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Costumbres...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3458</th>\n      <td>Ya decía yo que veía menos moros</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3459</th>\n      <td>+1. Como lo sabes...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3460</th>\n      <td>Seguirán cobrando paguitas en Marruecos,expoli...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3461</th>\n      <td>pobres, se arriesgan en pateras porque huyen d...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3462</th>\n      <td>Yo me quiero escapar también, dan paguita al l...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>3463 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "sample_data = data[[\"comment\", \"toxicity\",\"toxicity_level\"]]\n",
    "sample_data"
   ]
  },
  {
   "source": [
    "#### Leer tweets y preprocesado "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_preprocessing_not_tokenized(tweet):\n",
    "    tweet = tweet.lower() # Se empieza pasando todos los mensajes a minúsculas\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\" ,tweet , flags=re.MULTILINE) # Quitar URLs\n",
    "    tweet = re.sub(r\"\\@\\w+|\\#\", \"\", tweet) # Quitar @ y #\n",
    "    tweet = re.sub(r\"[\\U00010000-\\U0010ffff]|:\\)|:\\(|XD|xD|;\\)|:,\\(|:D|D:\", \"\", tweet) # Quitar emojis y emoticones\n",
    "    tweet = tweet.translate(str.maketrans('', '', string.punctuation)) # Quitar signos de puntuación\n",
    "    tokenized_tweets = word_tokenize(tweet)\n",
    "    filtered_tweets = [word for word in tokenized_tweets if not word in set(stopwords.words('spanish'))] # Quitar stopwords y filtrar\n",
    "    \n",
    "    stemming = PorterStemmer() # Inicializamos PorterStemmer para obtener la raíz de cada una de las palabras\n",
    "    stemmed_tweets = [stemming.stem(word) for word in filtered_tweets]\n",
    "    lemmatization = WordNetLemmatizer() # Inicializamos el Lemmatizer para obtener los lemas de las palabras\n",
    "    lemma_tweets = [lemmatization.lemmatize(word, pos='a') for word in stemmed_tweets] \n",
    "    return lemma_tweets # NO TOKENIZADO\n",
    "\n",
    "preprocessing = lambda x: tweet_preprocessing_not_tokenized(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-45-3c4e5d0f187f>:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  sample_data['comment'] = pd.DataFrame(sample_data[\"comment\"].apply(preprocessing))\n"
     ]
    }
   ],
   "source": [
    "sample_data['comment'] = pd.DataFrame(sample_data[\"comment\"].apply(preprocessing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                comment  toxicity  \\\n",
       "0                                 [pensó, zumo, restar]         1   \n",
       "1                         [gusta, afeitado, seco, gent]         1   \n",
       "2     [asi, gusta, maten, alta, mar, ma, inmigrant, ...         1   \n",
       "3     [loss, ma, valient, mejor, cortan, cabeza, soc...         1   \n",
       "4                                            [costumbr]         1   \n",
       "...                                                 ...       ...   \n",
       "3458                          [decía, veía, meno, moro]         1   \n",
       "3459                                          [1, sabe]         0   \n",
       "3460  [seguirán, cobrando, paguita, marruecosexpolia...         1   \n",
       "3461  [pobr, arriesgan, patera, huyen, guerr, ohhh, ...         1   \n",
       "3462            [quiero, escapar, dan, paguita, llegar]         1   \n",
       "\n",
       "      toxicity_level  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  2  \n",
       "3                  1  \n",
       "4                  1  \n",
       "...              ...  \n",
       "3458               1  \n",
       "3459               0  \n",
       "3460               1  \n",
       "3461               1  \n",
       "3462               1  \n",
       "\n",
       "[3463 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment</th>\n      <th>toxicity</th>\n      <th>toxicity_level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[pensó, zumo, restar]</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[gusta, afeitado, seco, gent]</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[asi, gusta, maten, alta, mar, ma, inmigrant, ...</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[loss, ma, valient, mejor, cortan, cabeza, soc...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[costumbr]</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3458</th>\n      <td>[decía, veía, meno, moro]</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3459</th>\n      <td>[1, sabe]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3460</th>\n      <td>[seguirán, cobrando, paguita, marruecosexpolia...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3461</th>\n      <td>[pobr, arriesgan, patera, huyen, guerr, ohhh, ...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3462</th>\n      <td>[quiero, escapar, dan, paguita, llegar]</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>3463 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}