{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practica5_Sesion4.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKSU2s8wbxML"
      },
      "source": [
        "# Detection of TOXicity in comments in Spanish (DETOXIS 2021)\n",
        "\n",
        "## SESIÓN 2.4: Combinación de clasificadores\n",
        "\n",
        "### Realizado por Álvaro Mazcuñán y Miquel Marín"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HRQ-c0SOQWy"
      },
      "source": [
        "**IMPORTANTE**: En esta última práctica se ha presentado el modelo BETO junto con las técnicas de combinación de clasificadores. No obstante, aunque no figure en esta entrega, la realización de la variante BERT para tweets en castellano (BETO) se implementó ya en la anterior entrega (Sesión 3: Clasificador basado en BERT y evaluación).\n",
        "\n",
        "A continuación se pasaría a mostrar lo que se ha realizado para obtener la combinación de modelos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QH8XFIRBc3Xh"
      },
      "source": [
        "#### Librerías"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGoV4L2XN3Bf"
      },
      "source": [
        "Se importan las mismas librerías que se utilizaron en la parte anterior. Además se añaden las necesarias como es la de StackingClassifier para poder evaluar la combinación de clasificadores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IZzXwX5c3pz"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import warnings"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTxI7Jeic_kg"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJrwNdUYdA_d",
        "outputId": "345e5e88-c21e-4102-9605-92b21c9ba5bb"
      },
      "source": [
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxR4GAZPBvdn"
      },
      "source": [
        "#### Carga de datos DETOXIS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUWUv-7FOKUw"
      },
      "source": [
        "Se pasan a cargar los datos de DETOXIS que se han utilizado a lo largo de todas las entregas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "PeuU-nycdCNB",
        "outputId": "8b3c5313-2d5e-4426-feae-d817b8595929"
      },
      "source": [
        "df = pd.read_csv(\"DATASET_DETOXIS.csv\")\n",
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topic</th>\n",
              "      <th>thread_id</th>\n",
              "      <th>comment_id</th>\n",
              "      <th>reply_to</th>\n",
              "      <th>comment_level</th>\n",
              "      <th>comment</th>\n",
              "      <th>argumentation</th>\n",
              "      <th>constructiveness</th>\n",
              "      <th>positive_stance</th>\n",
              "      <th>negative_stance</th>\n",
              "      <th>target_person</th>\n",
              "      <th>target_group</th>\n",
              "      <th>stereotype</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>mockery</th>\n",
              "      <th>insult</th>\n",
              "      <th>improper_language</th>\n",
              "      <th>aggressiveness</th>\n",
              "      <th>intolerance</th>\n",
              "      <th>toxicity</th>\n",
              "      <th>toxicity_level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CR</td>\n",
              "      <td>0_000</td>\n",
              "      <td>0_002</td>\n",
              "      <td>0_002</td>\n",
              "      <td>1</td>\n",
              "      <td>Pensó: Zumo para restar.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CR</td>\n",
              "      <td>0_001</td>\n",
              "      <td>0_003</td>\n",
              "      <td>0_003</td>\n",
              "      <td>1</td>\n",
              "      <td>Como les gusta el afeitado en seco a esta gente.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CR</td>\n",
              "      <td>0_002</td>\n",
              "      <td>0_004</td>\n",
              "      <td>0_004</td>\n",
              "      <td>1</td>\n",
              "      <td>asi me gusta, que se maten entre ellos y en al...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CR</td>\n",
              "      <td>0_003</td>\n",
              "      <td>0_005</td>\n",
              "      <td>0_005</td>\n",
              "      <td>1</td>\n",
              "      <td>Loss mas valientes, los que mejor cortan nuest...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CR</td>\n",
              "      <td>0_004</td>\n",
              "      <td>0_006</td>\n",
              "      <td>0_006</td>\n",
              "      <td>1</td>\n",
              "      <td>Costumbres...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3458</th>\n",
              "      <td>MI</td>\n",
              "      <td>20_134</td>\n",
              "      <td>20_164</td>\n",
              "      <td>20_164</td>\n",
              "      <td>1</td>\n",
              "      <td>Ya decía yo que veía menos moros</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3459</th>\n",
              "      <td>MI</td>\n",
              "      <td>20_006</td>\n",
              "      <td>20_165</td>\n",
              "      <td>20_008</td>\n",
              "      <td>2</td>\n",
              "      <td>+1. Como lo sabes...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3460</th>\n",
              "      <td>MI</td>\n",
              "      <td>20_135</td>\n",
              "      <td>20_166</td>\n",
              "      <td>20_166</td>\n",
              "      <td>1</td>\n",
              "      <td>Seguirán cobrando paguitas en Marruecos,expoli...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3461</th>\n",
              "      <td>MI</td>\n",
              "      <td>20_136</td>\n",
              "      <td>20_167</td>\n",
              "      <td>20_167</td>\n",
              "      <td>1</td>\n",
              "      <td>pobres, se arriesgan en pateras porque huyen d...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3462</th>\n",
              "      <td>MI</td>\n",
              "      <td>20_137</td>\n",
              "      <td>20_168</td>\n",
              "      <td>20_168</td>\n",
              "      <td>1</td>\n",
              "      <td>Yo me quiero escapar también, dan paguita al l...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3463 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     topic thread_id comment_id  ... intolerance  toxicity toxicity_level\n",
              "0       CR     0_000      0_002  ...           0         1              1\n",
              "1       CR     0_001      0_003  ...           0         1              1\n",
              "2       CR     0_002      0_004  ...           1         1              2\n",
              "3       CR     0_003      0_005  ...           0         1              1\n",
              "4       CR     0_004      0_006  ...           0         1              1\n",
              "...    ...       ...        ...  ...         ...       ...            ...\n",
              "3458    MI    20_134     20_164  ...           0         1              1\n",
              "3459    MI    20_006     20_165  ...           0         0              0\n",
              "3460    MI    20_135     20_166  ...           1         1              1\n",
              "3461    MI    20_136     20_167  ...           0         1              1\n",
              "3462    MI    20_137     20_168  ...           0         1              1\n",
              "\n",
              "[3463 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "Er9umq1bdNWT",
        "outputId": "8dac17f5-a69d-402c-e1ac-e3d4ab0ace26"
      },
      "source": [
        "sample_data = df[[\"comment\", \"toxicity\",\"toxicity_level\"]]\n",
        "sample_data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>toxicity</th>\n",
              "      <th>toxicity_level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pensó: Zumo para restar.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Como les gusta el afeitado en seco a esta gente.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>asi me gusta, que se maten entre ellos y en al...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Loss mas valientes, los que mejor cortan nuest...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Costumbres...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3458</th>\n",
              "      <td>Ya decía yo que veía menos moros</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3459</th>\n",
              "      <td>+1. Como lo sabes...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3460</th>\n",
              "      <td>Seguirán cobrando paguitas en Marruecos,expoli...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3461</th>\n",
              "      <td>pobres, se arriesgan en pateras porque huyen d...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3462</th>\n",
              "      <td>Yo me quiero escapar también, dan paguita al l...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3463 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                comment  ...  toxicity_level\n",
              "0                              Pensó: Zumo para restar.  ...               1\n",
              "1      Como les gusta el afeitado en seco a esta gente.  ...               1\n",
              "2     asi me gusta, que se maten entre ellos y en al...  ...               2\n",
              "3     Loss mas valientes, los que mejor cortan nuest...  ...               1\n",
              "4                                         Costumbres...  ...               1\n",
              "...                                                 ...  ...             ...\n",
              "3458                   Ya decía yo que veía menos moros  ...               1\n",
              "3459                               +1. Como lo sabes...  ...               0\n",
              "3460  Seguirán cobrando paguitas en Marruecos,expoli...  ...               1\n",
              "3461  pobres, se arriesgan en pateras porque huyen d...  ...               1\n",
              "3462  Yo me quiero escapar también, dan paguita al l...  ...               1\n",
              "\n",
              "[3463 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oF8QrtaB3vx"
      },
      "source": [
        "#### Leer tweets y preprocesado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qnv6yQczQzYM"
      },
      "source": [
        "Se pasan a leer y preprocesar cada uno de los tweets que disponemos en la base de datos mediante la función de limpieza que se ha ido utilizando a lo largo de todas las entregas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIhwu91ldSao"
      },
      "source": [
        "def tweet_preprocessing_not_tokenized(tweet):\n",
        "    tweet = tweet.lower() # Se empieza pasando todos los mensajes a minúsculas\n",
        "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\" ,tweet , flags=re.MULTILINE) # Quitar URLs\n",
        "    tweet = re.sub(r\"\\@\\w+|\\#\", \"\", tweet) # Quitar @ y #\n",
        "    tweet = re.sub(r\"[\\U00010000-\\U0010ffff]|:\\)|:\\(|XD|xD|;\\)|:,\\(|:D|D:\", \"\", tweet) # Quitar emojis y emoticones\n",
        "    tweet = tweet.translate(str.maketrans('', '', string.punctuation)) # Quitar signos de puntuación\n",
        "    tokenized_tweets = word_tokenize(tweet)\n",
        "    filtered_tweets = [word for word in tokenized_tweets if not word in set(stopwords.words('spanish'))] # Quitar stopwords y filtrar\n",
        "    \n",
        "    stemming = PorterStemmer() # Inicializamos PorterStemmer para obtener la raíz de cada una de las palabras\n",
        "    stemmed_tweets = [stemming.stem(word) for word in filtered_tweets]\n",
        "    lemmatization = WordNetLemmatizer() # Inicializamos el Lemmatizer para obtener los lemas de las palabras\n",
        "    lemma_tweets = [lemmatization.lemmatize(word, pos='a') for word in stemmed_tweets] \n",
        "    return \" \".join(lemma_tweets) # NO TOKENIZADO\n",
        "\n",
        "preprocessing = lambda x: tweet_preprocessing_not_tokenized(x)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OTj3jNIdVeE"
      },
      "source": [
        "sample_data['comment'] = pd.DataFrame(sample_data[\"comment\"].apply(preprocessing))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kij4FA8xFIfy"
      },
      "source": [
        "#### Variable `Toxicity`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSYIE6z9B_ti"
      },
      "source": [
        "#### Dividir el corpus en conjunto de entrenamiento y test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOdhQglMdcKq"
      },
      "source": [
        "train_X, test_X, train_Y, test_Y = train_test_split(sample_data['comment'], sample_data['toxicity'], test_size=0.3)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0EIMRJBC5eu"
      },
      "source": [
        "### Extracción de características"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmAX3T8OC-GK"
      },
      "source": [
        "#### Term Frequency - Inverse Document Frequency (TF-IDF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jaOxu8Ti467"
      },
      "source": [
        "tfidf_vect = TfidfVectorizer()\n",
        "tfidf_vect.fit(sample_data['comment'])\n",
        "train_X_Tfidf = tfidf_vect.transform(train_X)\n",
        "test_X_Tfidf = tfidf_vect.transform(test_X)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZyy4MFCDjdn"
      },
      "source": [
        "#### Support Vector Machine (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNXcGUe-jYzO",
        "outputId": "5bd3b6c8-a352-4f21-cc09-b2fd8fc0123c"
      },
      "source": [
        "svm_clf = SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
        "svm_clf.fit(train_X_Tfidf,train_Y)\n",
        "\n",
        "y_train_pred = svm_clf.predict(train_X_Tfidf)\n",
        "y_test_pred = svm_clf.predict(test_X_Tfidf)\n",
        "\n",
        "# Training set performance\n",
        "svm_train_accuracy = accuracy_score(train_Y, y_train_pred) # Calculate Accuracy\n",
        "svm_train_f1 = f1_score(train_Y, y_train_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "# Test set performance\n",
        "svm_test_accuracy = accuracy_score(test_Y, y_test_pred) # Calculate Accuracy\n",
        "svm_test_f1 = f1_score(test_Y, y_test_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "print('Model performance for Training set')\n",
        "print('- Accuracy: %s' % svm_train_accuracy)\n",
        "print('- F1 score: %s' % svm_train_f1)\n",
        "print('----------------------------------')\n",
        "print('Model performance for Test set')\n",
        "print('- Accuracy: %s' % svm_test_accuracy)\n",
        "print('- F1 score: %s' % svm_test_f1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model performance for Training set\n",
            "- Accuracy: 0.9451320132013201\n",
            "- F1 score: 0.9439714298372067\n",
            "----------------------------------\n",
            "Model performance for Test set\n",
            "- Accuracy: 0.7670837343599615\n",
            "- F1 score: 0.7381633922707466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_58bAoGmEkdG"
      },
      "source": [
        "#### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsZezqfakXhw",
        "outputId": "ea8e7a98-b9fd-4b7c-942b-ccb67177481b"
      },
      "source": [
        "tree_clf = DecisionTreeClassifier(max_depth=4)\n",
        "tree_clf.fit(train_X_Tfidf,train_Y)\n",
        "\n",
        "y_train_pred = tree_clf.predict(train_X_Tfidf)\n",
        "y_test_pred = tree_clf.predict(test_X_Tfidf)\n",
        "\n",
        "# Training set performance\n",
        "dt_train_accuracy = accuracy_score(train_Y, y_train_pred) # Calculate Accuracy\n",
        "dt_train_f1 = f1_score(train_Y, y_train_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "# Test set performance\n",
        "dt_test_accuracy = accuracy_score(test_Y, y_test_pred) # Calculate Accuracy\n",
        "dt_test_f1 = f1_score(test_Y, y_test_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "print('Model performance for Training set')\n",
        "print('- Accuracy: %s' % dt_train_accuracy)\n",
        "print('- F1 score: %s' % dt_train_f1)\n",
        "print('----------------------------------')\n",
        "print('Model performance for Test set')\n",
        "print('- Accuracy: %s' % dt_test_accuracy)\n",
        "print('- F1 score: %s' % dt_test_f1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model performance for Training set\n",
            "- Accuracy: 0.6984323432343235\n",
            "- F1 score: 0.6089207425922718\n",
            "----------------------------------\n",
            "Model performance for Test set\n",
            "- Accuracy: 0.7276227141482194\n",
            "- F1 score: 0.6509128557478479\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0ECO0A7EmrB"
      },
      "source": [
        "#### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cA0FgQl8lgej",
        "outputId": "3a752c1f-8fed-4c11-d1e3-ccfe032cf6b6"
      },
      "source": [
        "rf = RandomForestClassifier(n_estimators=10)\n",
        "rf.fit(train_X_Tfidf, train_Y)\n",
        "\n",
        "y_train_pred = rf.predict(train_X_Tfidf)\n",
        "y_test_pred = rf.predict(test_X_Tfidf)\n",
        "\n",
        "# Training set performance\n",
        "rf_train_accuracy = accuracy_score(train_Y, y_train_pred) # Calculate Accuracy\n",
        "rf_train_f1 = f1_score(train_Y, y_train_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "# Test set performance\n",
        "rf_test_accuracy = accuracy_score(test_Y, y_test_pred) # Calculate Accuracy\n",
        "rf_test_f1 = f1_score(test_Y, y_test_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "print('Model performance for Training set')\n",
        "print('- Accuracy: %s' % rf_train_accuracy)\n",
        "print('- F1 score: %s' % rf_train_f1)\n",
        "print('----------------------------------')\n",
        "print('Model performance for Test set')\n",
        "print('- Accuracy: %s' % rf_test_accuracy)\n",
        "print('- F1 score: %s' % rf_test_f1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model performance for Training set\n",
            "- Accuracy: 0.969059405940594\n",
            "- F1 score: 0.9686918838880257\n",
            "----------------------------------\n",
            "Model performance for Test set\n",
            "- Accuracy: 0.7401347449470644\n",
            "- F1 score: 0.7041506624562469\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHIEWuDDEon8"
      },
      "source": [
        "#### Perceptrón Multicapa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrw169svmUi_",
        "outputId": "888dfc4b-6ef3-4b97-e922-b9ff9d32c722"
      },
      "source": [
        "mlp = MLPClassifier(alpha=1, max_iter=1000)\n",
        "mlp.fit(train_X_Tfidf, train_Y)\n",
        "\n",
        "y_train_pred = mlp.predict(train_X_Tfidf)\n",
        "y_test_pred = mlp.predict(test_X_Tfidf)\n",
        "\n",
        "# Training set performance\n",
        "mlp_train_accuracy = accuracy_score(train_Y, y_train_pred) # Calculate Accuracy\n",
        "mlp_train_f1 = f1_score(train_Y, y_train_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "# Test set performance\n",
        "mlp_test_accuracy = accuracy_score(test_Y, y_test_pred) # Calculate Accuracy\n",
        "mlp_test_f1 = f1_score(test_Y, y_test_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "print('Model performance for Training set')\n",
        "print('- Accuracy: %s' % mlp_train_accuracy)\n",
        "print('- F1 score: %s' % mlp_train_f1)\n",
        "print('----------------------------------')\n",
        "print('Model performance for Test set')\n",
        "print('- Accuracy: %s' % mlp_test_accuracy)\n",
        "print('- F1 score: %s' % mlp_test_f1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model performance for Training set\n",
            "- Accuracy: 0.7978547854785478\n",
            "- F1 score: 0.7698127655902844\n",
            "----------------------------------\n",
            "Model performance for Test set\n",
            "- Accuracy: 0.737247353224254\n",
            "- F1 score: 0.6744482783075784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpkziaGyE0xn"
      },
      "source": [
        "#### Stacking model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfRS5BCIRL8w"
      },
      "source": [
        "En esta práctica se han presentado diferentes técnicas para combinar modelos y de esta forma poder obtener mejores resultados de los que se han ido obteniendo hasta el momento.\n",
        "\n",
        "De entre todas las opciones propuestas en dicha práctica, se ha decidido utilizar la técnica de Generalización apilada. Esta decisión se ha tomado en base a varios artículos/papers en los cuales se comenta que Stacking es una técnica muy utilizada para poder lidiar con los problemas de desbalanceo de clases tal y como ocurre en la segunda tarea: clasificar los tweets en función del nivel de toxicidad (variable `toxicity_level`).\n",
        "\n",
        "Para realizar Stacking, se han añadido los siguientes modelos:\n",
        "\n",
        "- SVM\n",
        "- DecisionTree\n",
        "- RandomForest\n",
        "- Multilayer Perceptron\n",
        "\n",
        "Por otra parte, se ha utilizado Logistic Regression como modelo final."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FA7IPYGqnF1o",
        "outputId": "7885096c-d89d-496f-d5d1-5cd2dbd75af6"
      },
      "source": [
        "estimator_list = [\n",
        "    ('svm_clf',svm_clf),\n",
        "    ('tree_clf',tree_clf),\n",
        "    ('rf',rf),\n",
        "    ('mlp',mlp) ]\n",
        "\n",
        "\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=estimator_list, final_estimator=LogisticRegression()\n",
        ")\n",
        "\n",
        "\n",
        "stack_model.fit(train_X_Tfidf, train_Y)\n",
        "\n",
        "\n",
        "y_train_pred = stack_model.predict(train_X_Tfidf)\n",
        "y_test_pred = stack_model.predict(test_X_Tfidf)\n",
        "\n",
        "# Training set model performance\n",
        "stack_model_train_accuracy = accuracy_score(train_Y, y_train_pred) # Calculate Accuracy\n",
        "stack_model_train_f1 = f1_score(train_Y, y_train_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "# Test set model performance\n",
        "stack_model_test_accuracy = accuracy_score(test_Y, y_test_pred) # Calculate Accuracy\n",
        "stack_model_test_f1 = f1_score(test_Y, y_test_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "print('Model performance for Training set')\n",
        "print('- Accuracy: %s' % stack_model_train_accuracy)\n",
        "print('- F1 score: %s' % stack_model_train_f1)\n",
        "print('----------------------------------')\n",
        "print('Model performance for Test set')\n",
        "print('- Accuracy: %s' % stack_model_test_accuracy)\n",
        "print('- F1 score: %s' % stack_model_test_f1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model performance for Training set\n",
            "- Accuracy: 0.9834983498349835\n",
            "- F1 score: 0.9834281900575487\n",
            "----------------------------------\n",
            "Model performance for Test set\n",
            "- Accuracy: 0.7718960538979788\n",
            "- F1 score: 0.756802362938718\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk2czgL5oq5-"
      },
      "source": [
        "acc_train_list = {\n",
        "'svm_rbf': svm_train_accuracy,\n",
        "'tree_clf': dt_train_accuracy,\n",
        "'rf': rf_train_accuracy,\n",
        "'mlp': mlp_train_accuracy,\n",
        "'stack_model': stack_model_train_accuracy}\n",
        "\n",
        "\n",
        "f1_train_list = {\n",
        "'svm_rbf': svm_train_f1,\n",
        "'tree_clf': dt_train_f1,\n",
        "'rf': rf_train_f1,\n",
        "'mlp': mlp_train_f1,\n",
        "'stack_model': stack_model_train_f1}"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuYLIggepMgs"
      },
      "source": [
        "acc_test_list = {\n",
        "'svm_rbf': svm_test_accuracy,\n",
        "'tree_clf': dt_test_accuracy,\n",
        "'rf': rf_test_accuracy,\n",
        "'mlp': mlp_test_accuracy,\n",
        "'stack_model': stack_model_test_accuracy}\n",
        "\n",
        "\n",
        "f1_test_list = {\n",
        "'svm_rbf': svm_test_f1,\n",
        "'tree_clf': dt_test_f1,\n",
        "'rf': rf_test_f1,\n",
        "'mlp': mlp_test_f1,\n",
        "'stack_model': stack_model_test_f1}"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4S6GbkBFAX0"
      },
      "source": [
        "#### Resultados para Train y Test de la variable `Toxicity`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57jMjvFkW6Od"
      },
      "source": [
        "##### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "Ejq5R4fQouKp",
        "outputId": "89ea64fc-1214-4f68-834c-afc3ad72b0d0"
      },
      "source": [
        "acc_df = pd.DataFrame.from_dict(acc_train_list, orient='index', columns=['Accuracy'])\n",
        "f1_df = pd.DataFrame.from_dict(f1_train_list, orient='index', columns=['F1'])\n",
        "df = pd.concat([acc_df, f1_df], axis=1)\n",
        "df"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>svm_rbf</th>\n",
              "      <td>0.945132</td>\n",
              "      <td>0.943971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tree_clf</th>\n",
              "      <td>0.698432</td>\n",
              "      <td>0.608921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>0.969059</td>\n",
              "      <td>0.968692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mlp</th>\n",
              "      <td>0.797855</td>\n",
              "      <td>0.769813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stack_model</th>\n",
              "      <td>0.983498</td>\n",
              "      <td>0.983428</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Accuracy        F1\n",
              "svm_rbf      0.945132  0.943971\n",
              "tree_clf     0.698432  0.608921\n",
              "rf           0.969059  0.968692\n",
              "mlp          0.797855  0.769813\n",
              "stack_model  0.983498  0.983428"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB50mia1W71P"
      },
      "source": [
        "##### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "MUHmH4JspKq0",
        "outputId": "c9e8a263-a84f-4908-8913-c4d8f8bf4a49"
      },
      "source": [
        "acc_df_test = pd.DataFrame.from_dict(acc_test_list, orient='index', columns=['Accuracy'])\n",
        "f1_df_test = pd.DataFrame.from_dict(f1_test_list, orient='index', columns=['F1'])\n",
        "df_test = pd.concat([acc_df_test, f1_df_test], axis=1)\n",
        "df_test"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>svm_rbf</th>\n",
              "      <td>0.767084</td>\n",
              "      <td>0.738163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tree_clf</th>\n",
              "      <td>0.727623</td>\n",
              "      <td>0.650913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>0.740135</td>\n",
              "      <td>0.704151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mlp</th>\n",
              "      <td>0.737247</td>\n",
              "      <td>0.674448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stack_model</th>\n",
              "      <td>0.771896</td>\n",
              "      <td>0.756802</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Accuracy        F1\n",
              "svm_rbf      0.767084  0.738163\n",
              "tree_clf     0.727623  0.650913\n",
              "rf           0.740135  0.704151\n",
              "mlp          0.737247  0.674448\n",
              "stack_model  0.771896  0.756802"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7anIBhOFVNm"
      },
      "source": [
        "#### Variable `Toxicity_level`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az1_nR5bFh2N"
      },
      "source": [
        "#### Dividir el corpus en conjunto de entrenamiento y test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dcEIbtpFkCQ"
      },
      "source": [
        "train_X_, test_X_, train_Y_, test_Y_ = train_test_split(sample_data['comment'], sample_data['toxicity_level'], test_size=0.3)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipxWpwvBKBNT"
      },
      "source": [
        "### Extracción de características"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_5piZdgKFHa"
      },
      "source": [
        "#### Term Frequency - Inverse Document Frequency (TF-IDF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZFhAyhzKFeb"
      },
      "source": [
        "tfidf_vect_levels = TfidfVectorizer()\n",
        "tfidf_vect_levels.fit(sample_data['comment'])\n",
        "train_X_Tfidf_ = tfidf_vect_levels.transform(train_X_)\n",
        "test_X_Tfidf_ = tfidf_vect_levels.transform(test_X_)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxWwwO7rKajN"
      },
      "source": [
        "#### Support Vector Machine (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfGXmGz7KVq6",
        "outputId": "61b6d163-40ae-4e03-884f-7ad650c2f1ec"
      },
      "source": [
        "svm_clf_levels = SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
        "svm_clf_levels.fit(train_X_Tfidf_,train_Y_)\n",
        "\n",
        "y_train_pred_levels = svm_clf_levels.predict(train_X_Tfidf_)\n",
        "y_test_pred_levels = svm_clf_levels.predict(test_X_Tfidf_)\n",
        "\n",
        "# Training set performance\n",
        "svm_train_accuracy_levels = accuracy_score(train_Y_, y_train_pred_levels) # Calculate Accuracy\n",
        "svm_train_f1_levels = f1_score(train_Y_, y_train_pred_levels, average='weighted') # Calculate F1-score\n",
        "\n",
        "# Test set performance\n",
        "svm_test_accuracy_levels = accuracy_score(test_Y_, y_test_pred_levels) # Calculate Accuracy\n",
        "svm_test_f1_levels = f1_score(test_Y_, y_test_pred_levels, average='weighted') # Calculate F1-score\n",
        "\n",
        "print('Model performance for Training set')\n",
        "print('- Accuracy: %s' % svm_train_accuracy_levels)\n",
        "print('- F1 score: %s' % svm_train_f1_levels)\n",
        "print('----------------------------------')\n",
        "print('Model performance for Test set')\n",
        "print('- Accuracy: %s' % svm_test_accuracy_levels)\n",
        "print('- F1 score: %s' % svm_test_f1_levels)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model performance for Training set\n",
            "- Accuracy: 0.8679867986798679\n",
            "- F1 score: 0.8543835055270441\n",
            "----------------------------------\n",
            "Model performance for Test set\n",
            "- Accuracy: 0.6785370548604427\n",
            "- F1 score: 0.5867964652445087\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju-X0icCMhbK"
      },
      "source": [
        "#### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXd3V57sMnll",
        "outputId": "3bf404c7-3103-4b71-d043-1b589aeab334"
      },
      "source": [
        "tree_clf_levels = DecisionTreeClassifier(max_depth=4)\n",
        "tree_clf_levels.fit(train_X_Tfidf_,train_Y_)\n",
        "\n",
        "y_train_pred_levels = tree_clf_levels.predict(train_X_Tfidf_)\n",
        "y_test_pred_levels = tree_clf_levels.predict(test_X_Tfidf_)\n",
        "\n",
        "# Training set performance\n",
        "dt_train_accuracy_levels = accuracy_score(train_Y_, y_train_pred_levels) # Calculate Accuracy\n",
        "dt_train_f1_levels = f1_score(train_Y_, y_train_pred_levels, average='weighted') # Calculate F1-score\n",
        "\n",
        "# Test set performance\n",
        "dt_test_accuracy_levels = accuracy_score(test_Y_, y_test_pred_levels) # Calculate Accuracy\n",
        "dt_test_f1_levels = f1_score(test_Y_, y_test_pred_levels, average='weighted') # Calculate F1-score\n",
        "\n",
        "print('Model performance for Training set')\n",
        "print('- Accuracy: %s' % dt_train_accuracy_levels)\n",
        "print('- F1 score: %s' % dt_train_f1_levels)\n",
        "print('----------------------------------')\n",
        "print('Model performance for Test set')\n",
        "print('- Accuracy: %s' % dt_test_accuracy_levels)\n",
        "print('- F1 score: %s' % dt_test_f1_levels)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model performance for Training set\n",
            "- Accuracy: 0.7004950495049505\n",
            "- F1 score: 0.6082576383482872\n",
            "----------------------------------\n",
            "Model performance for Test set\n",
            "- Accuracy: 0.6631376323387873\n",
            "- F1 score: 0.5560463832751367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06JFoLKeN0Ha"
      },
      "source": [
        "#### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wCzJlWyN0ez",
        "outputId": "879ea1ba-1db6-46fd-df56-5fb23887b56e"
      },
      "source": [
        "rf_levels = RandomForestClassifier(n_estimators=10)\n",
        "rf_levels.fit(train_X_Tfidf_, train_Y_)\n",
        "\n",
        "y_train_pred_levels = rf_levels.predict(train_X_Tfidf_)\n",
        "y_test_pred_levels = rf_levels.predict(test_X_Tfidf_)\n",
        "\n",
        "# Training set performance\n",
        "rf_train_accuracy_levels = accuracy_score(train_Y_, y_train_pred_levels) # Calculate Accuracy\n",
        "rf_train_f1_levels = f1_score(train_Y_, y_train_pred_levels, average='weighted') # Calculate F1-score\n",
        "\n",
        "# Test set performance\n",
        "rf_test_accuracy_levels = accuracy_score(test_Y_, y_test_pred_levels) # Calculate Accuracy\n",
        "rf_test_f1_levels = f1_score(test_Y_, y_test_pred_levels, average='weighted') # Calculate F1-score\n",
        "\n",
        "print('Model performance for Training set')\n",
        "print('- Accuracy: %s' % rf_train_accuracy_levels)\n",
        "print('- F1 score: %s' % rf_train_f1_levels)\n",
        "print('----------------------------------')\n",
        "print('Model performance for Test set')\n",
        "print('- Accuracy: %s' % rf_test_accuracy_levels)\n",
        "print('- F1 score: %s' % rf_test_f1_levels)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model performance for Training set\n",
            "- Accuracy: 0.9653465346534653\n",
            "- F1 score: 0.9648049717650516\n",
            "----------------------------------\n",
            "Model performance for Test set\n",
            "- Accuracy: 0.6785370548604427\n",
            "- F1 score: 0.5996636125418464\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0pq9a3LQW-d"
      },
      "source": [
        "#### Perceptrón Multicapa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaXKvUhsQZdP",
        "outputId": "e0adf1e1-f484-4eca-c4cb-a7e5343fc1b7"
      },
      "source": [
        "mlp_levels = MLPClassifier(alpha=1, max_iter=1000)\n",
        "mlp_levels.fit(train_X_Tfidf_, train_Y_)\n",
        "\n",
        "y_train_pred_levels = mlp_levels.predict(train_X_Tfidf_)\n",
        "y_test_pred_levels = mlp_levels.predict(test_X_Tfidf_)\n",
        "\n",
        "# Training set performance\n",
        "mlp_train_accuracy_levels = accuracy_score(train_Y_, y_train_pred_levels) # Calculate Accuracy\n",
        "mlp_train_f1_levels = f1_score(train_Y_, y_train_pred_levels, average='weighted') # Calculate F1-score\n",
        "\n",
        "# Test set performance\n",
        "mlp_test_accuracy_levels = accuracy_score(test_Y_, y_test_pred_levels) # Calculate Accuracy\n",
        "mlp_test_f1_levels = f1_score(test_Y_, y_test_pred_levels, average='weighted') # Calculate F1-score\n",
        "\n",
        "print('Model performance for Training set')\n",
        "print('- Accuracy: %s' % mlp_train_accuracy_levels)\n",
        "print('- F1 score: %s' % mlp_train_f1_levels)\n",
        "print('----------------------------------')\n",
        "print('Model performance for Test set')\n",
        "print('- Accuracy: %s' % mlp_test_accuracy_levels)\n",
        "print('- F1 score: %s' % mlp_test_f1_levels)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model performance for Training set\n",
            "- Accuracy: 0.7887788778877888\n",
            "- F1 score: 0.7352735959523691\n",
            "----------------------------------\n",
            "Model performance for Test set\n",
            "- Accuracy: 0.6727622714148219\n",
            "- F1 score: 0.5747157919858865\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-_-CtABSa0k"
      },
      "source": [
        "#### Stacking model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbDww3v3SbRD",
        "outputId": "4f2c87f6-23c8-4f00-9b00-778d60b7c8ac"
      },
      "source": [
        "estimator_list_levels = [\n",
        "    ('svm_clf_levels',svm_clf_levels),\n",
        "    ('tree_clf_levels',tree_clf_levels),\n",
        "    ('rf_levels',rf_levels),\n",
        "    ('mlp_levels',mlp_levels) ]\n",
        "\n",
        "\n",
        "stack_model_levels = StackingClassifier(\n",
        "    estimators=estimator_list_levels, final_estimator=LogisticRegression()\n",
        ")\n",
        "\n",
        "\n",
        "stack_model_levels.fit(train_X_Tfidf_, train_Y_)\n",
        "\n",
        "\n",
        "y_train_pred_levels = stack_model_levels.predict(train_X_Tfidf_)\n",
        "y_test_pred_levels = stack_model_levels.predict(test_X_Tfidf_)\n",
        "\n",
        "# Training set model performance\n",
        "stack_model_train_accuracy_levels = accuracy_score(train_Y_, y_train_pred_levels) # Calculate Accuracy\n",
        "stack_model_train_f1_levels = f1_score(train_Y_, y_train_pred_levels, average='weighted') # Calculate F1-score\n",
        "\n",
        "# Test set model performance\n",
        "stack_model_test_accuracy_levels = accuracy_score(test_Y_, y_test_pred_levels) # Calculate Accuracy\n",
        "stack_model_test_f1_levels = f1_score(test_Y_, y_test_pred_levels, average='weighted') # Calculate F1-score\n",
        "\n",
        "print('Model performance for Training set')\n",
        "print('- Accuracy: %s' % stack_model_train_accuracy_levels)\n",
        "print('- F1 score: %s' % stack_model_train_f1_levels)\n",
        "print('----------------------------------')\n",
        "print('Model performance for Test set')\n",
        "print('- Accuracy: %s' % stack_model_test_accuracy_levels)\n",
        "print('- F1 score: %s' % stack_model_test_f1_levels)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model performance for Training set\n",
            "- Accuracy: 0.9121287128712872\n",
            "- F1 score: 0.902785330185105\n",
            "----------------------------------\n",
            "Model performance for Test set\n",
            "- Accuracy: 0.6948989412897016\n",
            "- F1 score: 0.6247262037201117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSRkoPI1U8Go"
      },
      "source": [
        "acc_train_list_levels = {\n",
        "'svm_rbf': svm_train_accuracy_levels,\n",
        "'tree_clf': dt_train_accuracy_levels,\n",
        "'rf': rf_train_accuracy_levels,\n",
        "'mlp': mlp_train_accuracy_levels,\n",
        "'stack_model': stack_model_train_accuracy_levels}\n",
        "\n",
        "\n",
        "f1_train_list_levels = {\n",
        "'svm_rbf': svm_train_f1_levels,\n",
        "'tree_clf': dt_train_f1_levels,\n",
        "'rf': rf_train_f1_levels,\n",
        "'mlp': mlp_train_f1_levels,\n",
        "'stack_model': stack_model_train_f1_levels}"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBqhROVqVCyY"
      },
      "source": [
        "acc_test_list_levels = {\n",
        "'svm_rbf': svm_test_accuracy_levels,\n",
        "'tree_clf': dt_test_accuracy_levels,\n",
        "'rf': rf_test_accuracy_levels,\n",
        "'mlp': mlp_test_accuracy_levels,\n",
        "'stack_model': stack_model_test_accuracy_levels}\n",
        "\n",
        "\n",
        "f1_test_list_levels = {\n",
        "'svm_rbf': svm_test_f1_levels,\n",
        "'tree_clf': dt_test_f1_levels,\n",
        "'rf': rf_test_f1_levels,\n",
        "'mlp': mlp_test_f1_levels,\n",
        "'stack_model': stack_model_test_f1_levels}"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE0PJKq-V210"
      },
      "source": [
        "#### Resultados para Train y Test de la variable `Toxicity_level`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzfxSglbW_gx"
      },
      "source": [
        "##### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "VZXAGFpDVOry",
        "outputId": "2b10e2c1-f43b-42f9-bbd9-c75f835492b2"
      },
      "source": [
        "acc_df_levels = pd.DataFrame.from_dict(acc_train_list_levels, orient='index', columns=['Accuracy'])\n",
        "f1_df_levels = pd.DataFrame.from_dict(f1_train_list_levels, orient='index', columns=['F1'])\n",
        "df_levels = pd.concat([acc_df_levels, f1_df_levels], axis=1)\n",
        "df_levels"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>svm_rbf</th>\n",
              "      <td>0.867987</td>\n",
              "      <td>0.854384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tree_clf</th>\n",
              "      <td>0.700495</td>\n",
              "      <td>0.608258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>0.965347</td>\n",
              "      <td>0.964805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mlp</th>\n",
              "      <td>0.788779</td>\n",
              "      <td>0.735274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stack_model</th>\n",
              "      <td>0.912129</td>\n",
              "      <td>0.902785</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Accuracy        F1\n",
              "svm_rbf      0.867987  0.854384\n",
              "tree_clf     0.700495  0.608258\n",
              "rf           0.965347  0.964805\n",
              "mlp          0.788779  0.735274\n",
              "stack_model  0.912129  0.902785"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vdlk9bTXA6u"
      },
      "source": [
        "##### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "y9ZyZjBbVcHV",
        "outputId": "082280cd-01d1-4a20-acf9-382594615bd2"
      },
      "source": [
        "acc_df_test_levels = pd.DataFrame.from_dict(acc_test_list_levels, orient='index', columns=['Accuracy'])\n",
        "f1_df_test_levels = pd.DataFrame.from_dict(f1_test_list_levels, orient='index', columns=['F1'])\n",
        "df_test_levels = pd.concat([acc_df_test_levels, f1_df_test_levels], axis=1)\n",
        "df_test_levels"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>svm_rbf</th>\n",
              "      <td>0.678537</td>\n",
              "      <td>0.586796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tree_clf</th>\n",
              "      <td>0.663138</td>\n",
              "      <td>0.556046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>0.678537</td>\n",
              "      <td>0.599664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mlp</th>\n",
              "      <td>0.672762</td>\n",
              "      <td>0.574716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stack_model</th>\n",
              "      <td>0.694899</td>\n",
              "      <td>0.624726</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Accuracy        F1\n",
              "svm_rbf      0.678537  0.586796\n",
              "tree_clf     0.663138  0.556046\n",
              "rf           0.678537  0.599664\n",
              "mlp          0.672762  0.574716\n",
              "stack_model  0.694899  0.624726"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}